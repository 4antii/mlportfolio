{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные\n",
    "\n",
    "Данные в [архиве](https://drive.google.com/file/d/15o7fdxTgndoy6K-e7g8g1M2-bOOwqZPl/view?usp=sharing). В нём два файла:\n",
    "- `news_train.txt` тренировочное множество\n",
    "- `news_test.txt` тренировочное множество\n",
    "\n",
    "С некоторых новостных сайтов были загружены тексты новостей за период  несколько лет, причем каждая новость принаделжит к какой-то рубрике: `science`, `style`, `culture`, `life`, `economics`, `business`, `travel`, `forces`, `media`, `sport`.\n",
    "\n",
    "В каждой строке файла содержится метка рубрики, заголовок новостной статьи и сам текст статьи, например:\n",
    "\n",
    ">    **sport**&nbsp;&lt;tab&gt;&nbsp;**Сборная Канады по хоккею разгромила чехов**&nbsp;&lt;tab&gt;&nbsp;**Сборная Канады по хоккею крупно об...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача\n",
    "\n",
    "1. Обработать данные, получив для каждого текста набор токенов\n",
    "Обработать токены с помощью (один вариант из трех):\n",
    "    - pymorphy2\n",
    "    - русского [snowball стеммера](https://www.nltk.org/howto/stem.html)\n",
    "    - [SentencePiece](https://github.com/google/sentencepiece) или [Huggingface Tokenizers](https://github.com/huggingface/tokenizers)\n",
    "    \n",
    "    \n",
    "2. Обучить word embeddings (fastText, word2vec, gloVe) на тренировочных данных. Можно использовать [gensim](https://radimrehurek.com/gensim/models/word2vec.html) . Продемонстрировать семантические ассоциации. \n",
    "\n",
    "3. Реализовать алгоритм классификации, посчитать точноть на тестовых данных, подобрать гиперпараметры. Метод векторизации выбрать произвольно - можно использовать $tf-idf$ с понижением размерности (см. scikit-learn), можно использовать обученные на предыдущем шаге векторные представления, можно использовать [предобученные модели](https://rusvectores.org/ru/models/). Имейте ввиду, что простое \"усреднение\" токенов в тексте скорее всего не даст положительных результатов. Нужно реализовать два алгоритмов из трех:\n",
    "     - SVM\n",
    "     - наивный байесовский классификатор\n",
    "     - логистическая регрессия\n",
    "    \n",
    "\n",
    "4.* Реализуйте классификацию с помощью нейросетевых моделей. Например [RuBERT](http://docs.deeppavlov.ai/en/master/features/models/bert.html) или [ELMo](https://rusvectores.org/ru/models/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Импорты и препроцессинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "from nltk.stem.snowball import RussianStemmer \n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sport\\tРядом с олимпийским стадионом в Рио начались протесты\\tВ Рио-де-Жанейро рядом со стадионом «Маракана» накануне начала Олимпийских Игр проходит акция протеста, сообщает корреспондент «Ленты.ру». Полиция применила против демонстрантов слезоточивый газ.Как передает ТАСС, манифестанты, выступающие против использования бюджетных средств на организацию Олимпиады в Бразилии, подожгли национальный флаг и с его помощью имитировали эстафету олимпийского огня.Торжественная церемония открытия Олимпиады стартовала в 20:00 (02:00 мск). Игры в Рио будут проходить до 21 августа.\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lines = list(open('../data/news_train.txt', 'r', encoding='utf-8'))\n",
    "test_lines = list(open('../data/news_test.txt', 'r', encoding='utf-8'))\n",
    "stop_words = set(stopwords.words(\"russian\"))\n",
    "random.shuffle(train_lines)\n",
    "random.shuffle(test_lines)\n",
    "train_lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://drive.google.com/file/d/1mG3tPS_59pANrgwd6T2IgnHWgph4vYbg/view?usp=sharing'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'https://drive.google.com/file/d/1mG3tPS_59pANrgwd6T2IgnHWgph4vYbg/view?usp=sharing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(lines):\n",
    "    data = []\n",
    "    for line in lines: \n",
    "        dct = {}\n",
    "        lst = line.split('\\t')\n",
    "        dct['class'] = lst[0]\n",
    "        dct['header'] = re.findall(r'\\b\\w+\\b', lst[1].lower())\n",
    "        dct['header'] = [w for w in dct['header'] if not w in stop_words]\n",
    "        sentance_list = re.split(r\"[.!?]\", lst[2].lower())\n",
    "        text = []\n",
    "        for sen in sentance_list: \n",
    "            words = re.findall(r'\\b\\w+\\b', sen.lower())\n",
    "            words = [w for w in words if not w in stop_words]\n",
    "            if len(words) > 1: \n",
    "                text.append(words)\n",
    "        dct['text'] = text\n",
    "        data.append(dct)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = preprocess(train_lines)\n",
    "test_data = preprocess(test_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_data(data):\n",
    "    rs = RussianStemmer()\n",
    "    for d in tqdm(data): \n",
    "        d['header'] = [rs.stem(word) for word in d['header']]\n",
    "        d['text'] = [[rs.stem(word) for word in sentence] for sentence in d['text']]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f1f273d3924cebacdfeb4308c2a66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stem_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7541ca5f719c42f7a2b240a4b9bde605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stem_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class': 'economics', 'header': ['лукойл', 'реш', 'прода', 'сво', 'пенсион', 'фонд'], 'text': [['крупн', 'росс', 'частн', 'нефтян', 'компан', 'лукойл', 'ищет', 'покупател', 'принадлежа', 'пенсион', 'фонд', 'лукойл', 'гарант'], ['номер', '18', 'июл', 'пишет', 'газет', 'ведом', 'ссылк', 'неназва', 'участник', 'рынк'], ['сведен', 'изначальн', 'нпф', 'лукойл', 'гарант', 'прос', 'миллиард', 'доллар', 'однак', 'встреч', 'потенциальн', 'покупател', 'цен', 'сниж', 'втро'], ['дан', 'издан', 'соответств', 'переговор', 'ведет', 'управля', 'лукойл', 'гарант', 'ифд', 'капитал', 'принадлежа', 'виц', 'президент', 'лукойл', 'леонид', 'федун'], ['однак', 'председател', 'совет', 'директор', 'нпф', 'лукойл', 'гарант', 'александр', 'жирк', 'заяв', 'издан', 'известн', 'так', 'переговор'], ['указыва', 'собеседник', 'газет', 'лукойл', 'гарант', 'предлага', 'куп', 'фонд', 'миха', 'прохоров', 'онэкс', 'однак', 'последн', 'отказа', 'неясн', 'перспект', 'пенсион', 'реформ', 'котор', 'последн', 'врем', 'обсужда', 'правительств'], ['официальн', 'комментар', 'переговор', 'онэксим', 'дал'], ['негосударствен', 'пенсион', 'фонд', 'лукойл', 'гарант', 'основа', '1994', 'год'], ['клиент', 'явля', '2', '3', 'миллион', 'человек', 'актив', 'составля', '86', 'миллиард', 'рубл', 'числ', '70', 'миллиард', 'пенсион', 'накоплен', 'гражда'], ['нпф', 'лукойл', 'явля', 'трет', 'величин', 'росс', 'газфонд', 'благосостоян']]}\n"
     ]
    }
   ],
   "source": [
    "print(train_data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def header_to_text(data):\n",
    "    for obj in data: \n",
    "        obj['text'].insert(0, obj['header'])\n",
    "        del obj['header']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_concat = header_to_text(train_data)\n",
    "test_concat = header_to_text(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class': 'sport',\n",
       "  'text': [['бывш', 'сотрудник', 'роснефт', 'возглав', 'российск', 'биатлон'],\n",
       "   ['бывш',\n",
       "    'руководител',\n",
       "    'спортивн',\n",
       "    'клуб',\n",
       "    'роснефт',\n",
       "    'александр',\n",
       "    'кравц',\n",
       "    'избра',\n",
       "    'пост',\n",
       "    'президент',\n",
       "    'союз',\n",
       "    'биатлонист',\n",
       "    'росс',\n",
       "    'срок',\n",
       "    '2018',\n",
       "    'год'],\n",
       "   ['сообща', 'р', 'спорт'],\n",
       "   ['должност',\n",
       "    'директор',\n",
       "    'центр',\n",
       "    'спортивн',\n",
       "    'подготовк',\n",
       "    'сборн',\n",
       "    'команд',\n",
       "    'росс',\n",
       "    'смен',\n",
       "    'миллиардер',\n",
       "    'миха',\n",
       "    'прохоров',\n",
       "    'котор',\n",
       "    'пода',\n",
       "    'отставк',\n",
       "    'апрел',\n",
       "    'год'],\n",
       "   ['выбор', 'прошл', '20', 'ма', 'отчетн', 'конференц', 'сбр', 'москв'],\n",
       "   ['польз',\n",
       "    'кравцов',\n",
       "    'сво',\n",
       "    'кандидатур',\n",
       "    'снял',\n",
       "    'руководител',\n",
       "    'федерац',\n",
       "    'биатлон',\n",
       "    'москв',\n",
       "    'владимир',\n",
       "    'малин',\n",
       "    'виц',\n",
       "    'президент',\n",
       "    'сбр',\n",
       "    'виктор',\n",
       "    'майгур',\n",
       "    'двукратн',\n",
       "    'олимпийск',\n",
       "    'чемпион',\n",
       "    'дмитр',\n",
       "    'васил',\n",
       "    'заслужен',\n",
       "    'тренер',\n",
       "    'росс',\n",
       "    'дмитр',\n",
       "    'алексашин',\n",
       "    'геннад',\n",
       "    'раменск',\n",
       "    'такж',\n",
       "    'олимпийск',\n",
       "    'чемпион',\n",
       "    'евген',\n",
       "    'редькин'],\n",
       "   ['участ',\n",
       "    'выбор',\n",
       "    'отказа',\n",
       "    'руководител',\n",
       "    'биатлон',\n",
       "    'карел',\n",
       "    'алекс',\n",
       "    'ермаш',\n",
       "    'кравц',\n",
       "    'получ',\n",
       "    'абсолютн',\n",
       "    'большинств',\n",
       "    'голос',\n",
       "    'выигра',\n",
       "    'борьб',\n",
       "    'пост',\n",
       "    'глав',\n",
       "    'сбр'],\n",
       "   ['кравц',\n",
       "    '1999',\n",
       "    'го',\n",
       "    '2003',\n",
       "    'год',\n",
       "    'руковод',\n",
       "    'спортивн',\n",
       "    'клуб',\n",
       "    'роснефт',\n",
       "    'котор',\n",
       "    'обеспечива',\n",
       "    'подготовк',\n",
       "    'сборн',\n",
       "    'команд',\n",
       "    'биатлон',\n",
       "    'лыжн',\n",
       "    'гонк'],\n",
       "   ['2005',\n",
       "    'го',\n",
       "    'функционер',\n",
       "    'работа',\n",
       "    'центр',\n",
       "    'спортивн',\n",
       "    'подготовк',\n",
       "    'сборн',\n",
       "    'команд',\n",
       "    'росс',\n",
       "    '2014',\n",
       "    'год',\n",
       "    'глав',\n",
       "    'российск',\n",
       "    'делегац',\n",
       "    'олимпиад',\n",
       "    'соч']]},\n",
       " {'class': 'media',\n",
       "  'text': [['вежлив',\n",
       "    'поисков',\n",
       "    'запрос',\n",
       "    'британск',\n",
       "    'бабушк',\n",
       "    'умил',\n",
       "    'пользовател',\n",
       "    'соцсет'],\n",
       "   ['британец',\n",
       "    'бен',\n",
       "    'джон',\n",
       "    'опубликова',\n",
       "    'twitter',\n",
       "    'фотограф',\n",
       "    'компьютер',\n",
       "    'сво',\n",
       "    'бабушк',\n",
       "    'котор',\n",
       "    'формулир',\n",
       "    'запрос',\n",
       "    'google',\n",
       "    'очен',\n",
       "    'вежлив',\n",
       "    'форм'],\n",
       "   ['пост',\n",
       "    'выложен',\n",
       "    'сет',\n",
       "    '9',\n",
       "    'июн',\n",
       "    'подел',\n",
       "    'друг',\n",
       "    'друг',\n",
       "    'сем',\n",
       "    'тысяч',\n",
       "    'пользовател',\n",
       "    'отметк',\n",
       "    'нрав',\n",
       "    'запис',\n",
       "    'постав',\n",
       "    'десят',\n",
       "    'тысяч',\n",
       "    'человек'],\n",
       "   ['снимк',\n",
       "    'показа',\n",
       "    'строк',\n",
       "    'поиск',\n",
       "    'google',\n",
       "    'котор',\n",
       "    'пожил',\n",
       "    'женщин',\n",
       "    'написа',\n",
       "    'пожалуйст',\n",
       "    'перевед',\n",
       "    'римск',\n",
       "    'цифр',\n",
       "    'mcmxcviii'],\n",
       "   ['ben',\n",
       "    'john',\n",
       "    'push10ben',\n",
       "    '09',\n",
       "    'июн',\n",
       "    '2016',\n",
       "    '18',\n",
       "    '55',\n",
       "    'откр',\n",
       "    'ноутбук',\n",
       "    'мо',\n",
       "    'бабушк',\n",
       "    'увидел',\n",
       "    'пишет',\n",
       "    'пожалуйст',\n",
       "    'спасиб',\n",
       "    'гугл'],\n",
       "   ['прост', 'мог'],\n",
       "   ['комментар',\n",
       "    'пользовател',\n",
       "    'отмет',\n",
       "    'пенсионерк',\n",
       "    'заслужива',\n",
       "    'ответн',\n",
       "    'пожалуйст',\n",
       "    'поисковик',\n",
       "    'назва',\n",
       "    'образц',\n",
       "    'британск',\n",
       "    'вежлив'],\n",
       "   ['мног',\n",
       "    'пошут',\n",
       "    'так',\n",
       "    'уважительн',\n",
       "    'манер',\n",
       "    'общен',\n",
       "    'компьютер',\n",
       "    'придет',\n",
       "    'кстат',\n",
       "    'машин',\n",
       "    'захват',\n",
       "    'мир'],\n",
       "   ['издан',\n",
       "    'mashable',\n",
       "    'котор',\n",
       "    'обрат',\n",
       "    'вниман',\n",
       "    'пост',\n",
       "    'сред',\n",
       "    '15',\n",
       "    'июн',\n",
       "    'отмет',\n",
       "    'вежлив',\n",
       "    'бабушк',\n",
       "    'исполн',\n",
       "    '85',\n",
       "    'лет']]}]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_concat[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': 'culture',\n",
       " 'text': [['саш', 'барон', 'коэн', 'сыгра', 'саддам', 'хусейн'],\n",
       "  ['британск',\n",
       "   'комик',\n",
       "   'саш',\n",
       "   'барон',\n",
       "   'коэн',\n",
       "   'исполн',\n",
       "   'рол',\n",
       "   'иракск',\n",
       "   'диктатор',\n",
       "   'саддам',\n",
       "   'хусейн',\n",
       "   'сообща',\n",
       "   'агентств',\n",
       "   'associated',\n",
       "   'press',\n",
       "   'ссылк',\n",
       "   'компан',\n",
       "   'paramount',\n",
       "   'pictures'],\n",
       "  ['коэн',\n",
       "   'сыгра',\n",
       "   'главн',\n",
       "   'рол',\n",
       "   'фильм',\n",
       "   'диктатор',\n",
       "   'выход',\n",
       "   'котор',\n",
       "   'экра',\n",
       "   'запланирова',\n",
       "   'ма',\n",
       "   '2012',\n",
       "   'год',\n",
       "   'примет',\n",
       "   'участ',\n",
       "   'написан',\n",
       "   'сценар'],\n",
       "  ['основ',\n",
       "   'фильм',\n",
       "   'полож',\n",
       "   'книг',\n",
       "   'забиб',\n",
       "   'цар',\n",
       "   'авторств',\n",
       "   'котор',\n",
       "   'приписыва',\n",
       "   'сам',\n",
       "   'саддам',\n",
       "   'хусейн',\n",
       "   'хот',\n",
       "   'един',\n",
       "   'мнен',\n",
       "   'эт',\n",
       "   'повод'],\n",
       "  ['год',\n",
       "   'правлен',\n",
       "   'хусейн',\n",
       "   'рома',\n",
       "   'экранизирова',\n",
       "   'иракск',\n",
       "   'телевиден',\n",
       "   'кром',\n",
       "   'мотив',\n",
       "   'поставл',\n",
       "   'мюзикл'],\n",
       "  ['режиссер', 'картин', 'станет', 'ларр', 'чарльз'],\n",
       "  ['довод',\n",
       "   'работа',\n",
       "   'саш',\n",
       "   'барон',\n",
       "   'коэн',\n",
       "   'лент',\n",
       "   'борат',\n",
       "   'исследован',\n",
       "   'культур',\n",
       "   'америк',\n",
       "   'благ',\n",
       "   'славн',\n",
       "   'народ',\n",
       "   'казахста',\n",
       "   'брун'],\n",
       "  ['декабр',\n",
       "   '2010',\n",
       "   'год',\n",
       "   'стал',\n",
       "   'известн',\n",
       "   'саш',\n",
       "   'барон',\n",
       "   'коэн',\n",
       "   'исполн',\n",
       "   'главн',\n",
       "   'рол',\n",
       "   'американск',\n",
       "   'римейк',\n",
       "   'испанск',\n",
       "   'комед',\n",
       "   'торрент',\n",
       "   'глуп',\n",
       "   'рук',\n",
       "   'закон',\n",
       "   'torrente',\n",
       "   'el',\n",
       "   'brazo',\n",
       "   'tonto',\n",
       "   'de',\n",
       "   'la',\n",
       "   'ley'],\n",
       "  ['фильм', 'выйдет', 'прокат', 'пок', 'сообща'],\n",
       "  ['такж',\n",
       "   '2011',\n",
       "   'год',\n",
       "   'должн',\n",
       "   'нача',\n",
       "   'съемк',\n",
       "   'фильм',\n",
       "   'жизн',\n",
       "   'фредд',\n",
       "   'меркьюр',\n",
       "   'котор',\n",
       "   'коэн',\n",
       "   'сыгра',\n",
       "   'главн',\n",
       "   'рол']]}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_concat[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  W2V и семантические ассоциации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "all_sent = [sentance for item in train_data for sentance in item[\"text\"]]\n",
    "model = Word2Vec(all_sent, size=500, window=10 ,min_count=1, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('майкл', 0.9495384097099304), ('джон', 0.9455983638763428), ('питер', 0.9454224705696106), ('драм', 0.9363150596618652), ('дженнифер', 0.9345179200172424), ('капр', 0.9324065446853638), ('джонсон', 0.9305950999259949), ('комед', 0.9286341667175293), ('мартин', 0.9270502924919128), ('триллер', 0.9255245327949524)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=[\"джеймс\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ленинградск', 0.8552278280258179), ('новосибирск', 0.8272430300712585), ('петергбургск', 0.8240901231765747), ('екатеринбург', 0.8002661466598511), ('выставочн', 0.7967272400856018), ('ленобласт', 0.7816773653030396), ('нерп', 0.7778173685073853), ('градостроительств', 0.7762106657028198), ('соболев', 0.7690498232841492), ('новгород', 0.7657777070999146)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=[\"университет\", \"санкт\", \"петербург\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('гаджет', 0.9591737389564514), ('устройств', 0.9412131309509277), ('ос', 0.9362700581550598), ('модем', 0.9228483438491821), ('планшет', 0.9221930503845215), ('браузер', 0.9221010208129883), ('android', 0.919352650642395), ('смартфон', 0.9162595272064209), ('5s', 0.9113731384277344), ('ноутбук', 0.9107376337051392)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=[\"компьютер\",\"экран\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  TF-IDF from W2V "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "w2v = dict(zip(model.wv.index2word, model.wv.syn0))\n",
    "\n",
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(next(iter(word2vec.values())))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf,\n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = []\n",
    "train_Y = []\n",
    "test_X = []\n",
    "test_Y = []\n",
    "\n",
    "for x in train_concat: \n",
    "    train_X.append([j for i in x['text'] for j in i])\n",
    "    train_Y.append(x['class'])\n",
    "    \n",
    "for x in test_concat: \n",
    "    test_X.append([j for i in x['text'] for j in i])\n",
    "    test_Y.append(x['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('w2v tf-idf',\n",
       "                 <__main__.TfidfEmbeddingVectorizer object at 0x1a3dfd37d0>),\n",
       "                ('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('SVM',\n",
       "                 SVC(C=1, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='scale', kernel='linear', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_tfidf = Pipeline([\n",
    "    (\"w2v tf-idf\", TfidfEmbeddingVectorizer(w2v)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    (\"SVM\", SVC(kernel='linear', C=1,verbose=1))])   \n",
    "\n",
    "svm_tfidf.fit(train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_tfidf.score(train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.8533333333333334\n"
     ]
    }
   ],
   "source": [
    "predicts = svm_tfidf.predict(test_X)\n",
    "print(f\"accuracy = {(test_Y == predicts).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8548"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "bs_tfidf = Pipeline([\n",
    "    (\"w2v tf-idf\", TfidfEmbeddingVectorizer(w2v)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('PCA', PCA(n_components=100)),\n",
    "    (\"SVM\", LogisticRegression(max_iter=10000))])    \n",
    "bs_tfidf.fit(train_X,train_Y)\n",
    "\n",
    "bs_tfidf.score(train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.8496666666666667\n"
     ]
    }
   ],
   "source": [
    "predicts = bs_tfidf.predict(test_X)\n",
    "print(f\"accuracy = {(test_Y == predicts).mean()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
